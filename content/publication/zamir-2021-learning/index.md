---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Learning Digital Camera Pipeline for Extreme Low-Light Imaging
subtitle: ''
summary: ''
authors:
- admin
- Aditya Arora
- Salman Khan
- Fahad Shahbaz Khan
- Ling Shao
tags: []
categories: []
date: '2021-01-01'
lastmod: 2022-04-07T13:06:37+04:00
featured: false
draft: false


# Custom links (uncomment lines below)
links:
- name: arXiv
  url: https://arxiv.org/abs/1904.05939



# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-04-07T09:06:37.219612Z'
publication_types:
- '2'
abstract: 'In low-light conditions, a conventional camera imaging pipeline produces sub-optimal images that are usually dark and noisy due to a low photon count and low signal-to-noise ratio (SNR). We present a data-driven approach that learns the desired properties of well-exposed images and reflects them in images that are captured in extremely low ambient light environments, thereby significantly improving the visual quality of these low-light images. We propose a new loss function that exploits the characteristics of both pixel-wise and perceptual metrics, enabling our deep neural network to learn the camera processing pipeline to transform the short-exposure, low-light RAW sensor data to well-exposed sRGB images. The results show that our method outperforms the state-of-the-art according to psychophysical tests as well as pixel-wise standard metrics and recent learning-based perceptual image quality measures.'
publication: '*Neurocomputing*'
---
